{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How accurate is the OpenPrescribing Price Concession analysis, and can we improve it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price Concessions occur when pharmacies are unable to buy stock for the price listed in the Drug Tariff. These higher prices are usually due to stock availability issues.\n",
    "\n",
    "Currently the PSNC and Department of Health agree on a \"price concession\" at points during the month where the items have been dispensed.  This means that people are not able to find out the increased cost before dispensing.\n",
    "\n",
    "OpenPrescribing has a tool which allows an estimate of additional costs to be presented (and emailed) to users, based on a number of assumptions:\n",
    "\n",
    "- As the prescribing data is not available for the period, we use the data which is nearest available, which is usually two months beforehand.\n",
    "- We assume the national average percentage discount is 7.2%\n",
    "\n",
    "As the impact of price concessions are increasing, we thought it was time to undertake an analysis to see if our forecasting methodology was accurate enough for our users.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "from ebmdatalab import bq\n",
    "from ebmdatalab import charts\n",
    "import lxml\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import data from BigQuery to undertake the analysis.\n",
    "\n",
    "One of the issues with estimating the costs of price concessions is that the concession is at an individual pack size (or `VMPP`) level, whereas prescribing data is at presentation level, and therefore may have multiple pack sizes involved.  The SQL below includes a process to only select one pack size, and if there is a difference in the cost per unit, selects the one with the highest impact on spend.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 6341/6341 [00:00<00:00, 7510.37rows/s]\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "WITH \n",
    "  price_concession AS (--subquery to remove duplicates due to different pack sizes\n",
    "  SELECT\n",
    "    ncso.date AS month, --month\n",
    "    ncso.drug AS name,  -- drug name\n",
    "    vmpp.bnf_code AS bnf_code, --BNF code from VMPP table\n",
    "    ncso.price_pence AS pc_price_pence, --price concession cost per pack\n",
    "    dt.price_pence AS dt_price_pence, --Drug Tariff cost per pack\n",
    "    qtyval, --VMPP pack size\n",
    "    (ncso.price_pence - dt.price_pence)/qtyval AS increased_ppu --difference between concession and usual Drug Tariff price\n",
    "  FROM\n",
    "    ebmdatalab.dmd.ncsoconcession AS ncso --concession table\n",
    "  INNER JOIN\n",
    "    dmd.vmpp_full AS vmpp --VMPP table\n",
    "  ON\n",
    "    ncso.vmpp = vmpp.id\n",
    "  INNER JOIN\n",
    "    dmd.tariffprice AS dt -- Drug Tariff table\n",
    "  ON\n",
    "    ncso.vmpp = dt.vmpp\n",
    "    AND ncso.date = dt.date\n",
    "  QUALIFY ROW_NUMBER() OVER (PARTITION BY ncso.date, vmpp.bnf_code ORDER BY (ncso.price_pence - dt.price_pence)/qtyval DESC) = 1 -- for each bnf_code and pack size, calculates PPU difference and ranks in order. Takes the top value, therefore only keeping the highest impact pack size, and thereby removes duplicates for pack size\n",
    "  ORDER BY\n",
    "    ncso.date,\n",
    "    vmpp.bnf_code),\n",
    "  rx_data AS (--subquery to create prescribing calculations)\n",
    "  SELECT\n",
    "    rx.month AS month,\n",
    "    bnf_name,\n",
    "    bnf_code AS bnf_code,\n",
    "    SUM(quantity) AS quantity,\n",
    "    SUM(net_cost) AS nic,\n",
    "    SUM(actual_cost) AS actual_cost\n",
    "  FROM\n",
    "    ebmdatalab.hscic.normalised_prescribing AS rx\n",
    "  GROUP BY\n",
    "    rx.month,\n",
    "    bnf_name,\n",
    "    bnf_code)\n",
    "\n",
    "#main query\n",
    "\n",
    "SELECT\n",
    "  rx.month,\n",
    "  rx.bnf_name,\n",
    "  rx.bnf_code,\n",
    "  rx.quantity AS quantity,\n",
    "  rx_old.quantity AS quantity_2_months_previously ,\n",
    "  rx.nic,\n",
    "  rx.actual_cost,\n",
    "  dt_price_pence/(100*qtyval) AS normal_nic_per_unit, --calculates \"normal\" drug tariff price per unit\n",
    "  pc_price_pence/(100*qtyval) AS predicted_nic_per_unit -- calculates price concession predicted cost per unit\n",
    "FROM\n",
    "  rx_data AS rx\n",
    "INNER JOIN\n",
    "  rx_data AS rx_old -- data from two months previously\n",
    "ON\n",
    "  rx.bnf_code = rx_old.bnf_code\n",
    "  AND DATE(rx.month) = DATE_ADD(DATE(rx_old.month), INTERVAL 2 month) -- join to create data from two months ago\n",
    "INNER JOIN\n",
    "  price_concession AS ncso\n",
    "ON\n",
    "  DATE(rx.month) = ncso.month\n",
    "  AND rx.bnf_code = ncso.bnf_code\n",
    "WHERE\n",
    "    rx.month between '2017-01-01' and '2023-12-01'\n",
    "ORDER BY\n",
    "  rx.month \n",
    "\"\"\"\n",
    "\n",
    "exportfile = os.path.join(\"..\",\"data\",\"ncso_df.csv\") #defines name for cache file\n",
    "ncso_df = bq.cached_read(sql, csv_path=exportfile, use_cache=False) #uses BQ if changed, otherwise csv cache file\n",
    "ncso_df['month'] = pd.to_datetime(ncso_df['month']) #ensure dates are in datetimeformat\n",
    "ncso_df['normal_nic_per_unit'] = ncso_df['normal_nic_per_unit'].astype(float) #ensure in float format\n",
    "ncso_df['predicted_nic_per_unit'] = ncso_df['predicted_nic_per_unit'].astype(float) #ensure in float format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data imported, we can calculate the estimated impact of price concessions, using the same methodology that OpenPrescribing.net uses for initial predictions:\n",
    "- Using a fixed 7.2% [Average National Discount Percentage (NADP)](https://digital.nhs.uk/data-and-information/areas-of-interest/prescribing/practice-level-prescribing-in-england-a-summary/practice-level-prescribing-glossary-of-terms#actual-cost)\n",
    "- Using the latest data available at the time of estimate (usually two months behind)\n",
    "\n",
    "We calculate the costs by multiplying the unit quantity dispensed two months previously by the predicted cost per unit generated in the SQL above * 0.928.  This gives us the predicted actual cost, which we then compare to the actual amount spend in that month, and calculate the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate predicted costs for each drug\n",
    "ncso_df['predicted_actual_cost'] = ncso_df['quantity_2_months_previously'] * ncso_df['predicted_nic_per_unit'] * 0.928 #calculate predicted actual cost - multiply by 0.928 to get actual cost, using 2 months earlier quantity data as a prediction\n",
    "ncso_df['prediction_difference'] = ncso_df['actual_cost'] - ncso_df['predicted_actual_cost'] #calculate difference in costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create total monthly data\n",
    "ncso_sum_df=ncso_df.groupby(['month',])[['actual_cost','predicted_actual_cost', 'prediction_difference']].sum().reset_index()  #group data to show total per month\n",
    "\n",
    "ncso_sum_df['month'] = pd.to_datetime(ncso_sum_df['month'])\n",
    "ncso_sum_df['perc_difference'] = ncso_sum_df['prediction_difference'] / ncso_sum_df['actual_cost'] #calculate percentage difference\n",
    "ncso_sum_df.sort_values(by=['month']) #sort values by month for chart\n",
    "#ncso_sum_df['month'] = pd.to_datetime(ncso_sum_df['month'])\n",
    "#ncso_sum_df.set_index(inplace=True)\n",
    "ncso_sum_df['year'] = ncso_sum_df['month'].dt.year #add year column for grouping by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Percentage difference between forecasted price concession costs and actual spend')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "ValueError",
     "evalue": "view limit minimum -11500384.412686909 is less than 1 and is an invalid Matplotlib date value. This often happens if you pass a non-datetime value to an axis that has datetime units",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     41\u001b[0m             display(\n\u001b[1;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         ticksLight = _is_light([label.get_color()\n\u001b[0m\u001b[1;32m    181\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    181\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                                 \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                                 for label in axis.get_ticklabels()])\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mticksLight\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mticksLight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# there are one or more tick labels, all with the same lightness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_ticklabels\u001b[0;34m(self, minor, which)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mminor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklabels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m'Return a list of Text instances for the major ticklabels.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m         \u001b[0mlabels1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0mlabels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_major_ticks\u001b[0;34m(self, numticks)\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;34m'Get the tick instances; grow as necessary.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumticks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m             \u001b[0mnumticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajorTicks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnumticks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0;34m'Return the locations of the ticks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1428\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1429\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0;34m'Refresh internal information based on current limits.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewlim_to_dt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_locator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.1/lib/python3.8/site-packages/matplotlib/dates.py\u001b[0m in \u001b[0;36mviewlim_to_dt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmin\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             raise ValueError('view limit minimum {} is less than 1 and '\n\u001b[0m\u001b[1;32m   1196\u001b[0m                              \u001b[0;34m'is an invalid Matplotlib date value. This '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                              \u001b[0;34m'often happens if you pass a non-datetime '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: view limit minimum -11500384.412686909 is less than 1 and is an invalid Matplotlib date value. This often happens if you pass a non-datetime value to an axis that has datetime units"
     ]
    }
   ],
   "source": [
    "#create chart\n",
    "ax = ncso_sum_df.plot.bar(figsize = (12,6))\n",
    "ncso_sum_df['month'] = pd.to_datetime(ncso_sum_df['month'])\n",
    "ax.bar(ncso_sum_df['month'], ncso_sum_df['perc_difference'])\n",
    "ax.xaxis_date()\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "#ax.xaxis.set_major_formatter(plt.FixedFormatter(ncso_sum_df['month'].dt.strftime(\"%b %Y\"))) #this formats date as string in desired format for x axis, formats here: https://www.ibm.com/support/knowledgecenter/SS6V3G_5.3.1/com.ibm.help.gswapplintug.doc/GSW_strdate.html\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(1, decimals=None)) ##sets y axis labels as percent (and formats correctly i.e. x100)\n",
    "ax.set_title('Percentage difference between forecasted price concession costs and actual spend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [datetime.datetime(2010, 12, 1, 10, 0),\n",
    "    datetime.datetime(2011, 1, 4, 9, 0),\n",
    "    datetime.datetime(2011, 5, 5, 9, 0)]\n",
    "y = [4, 9, 2]\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(x, y, width=10)\n",
    "ax.xaxis_date()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the chart above, on a monthly basis the price concession data is usually accurate to within 5%.  The tool usually *overestimates* (i.e. a negative percentage) in February of each year, due to the difference in working or dispensing days between the actual month and the month used for prediction (December).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impact within Year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the tool is mainly used to estimate the impact on finances within the NHS due to price concessions, it is also useful to see how accurate the tool is over the whole year.  Aggregating the data over a financial year is also a useful way of describe the average accuracy, which will always be flucuating on a monthly basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#create year grouping\n",
    "#ncso_sum_df.reset_index(inplace=True)\n",
    "#ncso_sum_df= ncso_sum_df.reset_index('month', drop=True)\n",
    "ncso_fy_df = ncso_sum_df.groupby([\"year\"])[[\"actual_cost\",\"predicted_actual_cost\",\"prediction_difference\"]].sum() #groups by calendar year\n",
    "ncso_fy_df['perc_difference'] = ncso_fy_df['prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference \n",
    "ncso_fy_df.reset_index(inplace=True)\n",
    "#ncso_fy_df = ncso_fy_df.loc[ncso_fy_df[\"month\"].between(\"2017-04-01\", \"2023-12-31\")]\n",
    "#ncso_fy_df.groupby(ncso_fy_df[\"year\"]).filter(lambda x: len(x) == 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       month   actual_cost  predicted_actual_cost  \\\n",
      "0  2017-01-01 00:00:00+00:00  8.005775e+06           8.137176e+06   \n",
      "1  2017-02-01 00:00:00+00:00  7.423218e+06           8.383616e+06   \n",
      "2  2017-03-01 00:00:00+00:00  8.696441e+06           8.067864e+06   \n",
      "3  2017-04-01 00:00:00+00:00  6.301537e+06           6.166398e+06   \n",
      "4  2017-05-01 00:00:00+00:00  1.235804e+07           1.361402e+07   \n",
      "..                       ...           ...                    ...   \n",
      "79 2023-08-01 00:00:00+00:00  4.827618e+07           4.780226e+07   \n",
      "80 2023-09-01 00:00:00+00:00  4.444886e+07           4.335839e+07   \n",
      "81 2023-10-01 00:00:00+00:00  4.536343e+07           4.412045e+07   \n",
      "82 2023-11-01 00:00:00+00:00  4.802417e+07           4.468221e+07   \n",
      "83 2023-12-01 00:00:00+00:00  5.314364e+07           4.790112e+07   \n",
      "\n",
      "    prediction_difference  perc_difference  year  \n",
      "0           -1.314008e+05        -0.016413  2017  \n",
      "1           -9.603985e+05        -0.129378  2017  \n",
      "2            6.285765e+05         0.072280  2017  \n",
      "3            1.351393e+05         0.021445  2017  \n",
      "4           -1.255981e+06        -0.101633  2017  \n",
      "..                    ...              ...   ...  \n",
      "79           4.739233e+05         0.009817  2023  \n",
      "80           1.090470e+06         0.024533  2023  \n",
      "81           1.242983e+06         0.027401  2023  \n",
      "82           3.341962e+06         0.069589  2023  \n",
      "83           5.242522e+06         0.098648  2023  \n",
      "\n",
      "[84 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ncso_sum_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_cost</th>\n",
       "      <th>predicted_actual_cost</th>\n",
       "      <th>prediction_difference</th>\n",
       "      <th>perc_difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01</th>\n",
       "      <td>8.005775e+06</td>\n",
       "      <td>8.137176e+06</td>\n",
       "      <td>-1.314008e+05</td>\n",
       "      <td>-0.016413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-01</th>\n",
       "      <td>7.423218e+06</td>\n",
       "      <td>8.383616e+06</td>\n",
       "      <td>-9.603985e+05</td>\n",
       "      <td>-0.129378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-01</th>\n",
       "      <td>8.696441e+06</td>\n",
       "      <td>8.067864e+06</td>\n",
       "      <td>6.285765e+05</td>\n",
       "      <td>0.072280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-01</th>\n",
       "      <td>6.301537e+06</td>\n",
       "      <td>6.166398e+06</td>\n",
       "      <td>1.351393e+05</td>\n",
       "      <td>0.021445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>1.235804e+07</td>\n",
       "      <td>1.361402e+07</td>\n",
       "      <td>-1.255981e+06</td>\n",
       "      <td>-0.101633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             actual_cost  predicted_actual_cost  prediction_difference  \\\n",
       "month                                                                    \n",
       "2017-01-01  8.005775e+06           8.137176e+06          -1.314008e+05   \n",
       "2017-02-01  7.423218e+06           8.383616e+06          -9.603985e+05   \n",
       "2017-03-01  8.696441e+06           8.067864e+06           6.285765e+05   \n",
       "2017-04-01  6.301537e+06           6.166398e+06           1.351393e+05   \n",
       "2017-05-01  1.235804e+07           1.361402e+07          -1.255981e+06   \n",
       "\n",
       "            perc_difference  \n",
       "month                        \n",
       "2017-01-01        -0.016413  \n",
       "2017-02-01        -0.129378  \n",
       "2017-03-01         0.072280  \n",
       "2017-04-01         0.021445  \n",
       "2017-05-01        -0.101633  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncso_sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ncso_fy_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-024cfe47a33e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#create  year group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mncso_fy_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'perc_difference'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFixedFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncso_fy_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%Y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this formats date as string in desired format for x axis, formats here: https://www.ibm.com/support/knowledgecenter/SS6V3G_5.3.1/com.ibm.help.gswapplintug.doc/GSW_strdate.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_major_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPercentFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m##sets y axis labels as percent (and formats correctly i.e. x100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Year\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ncso_fy_df' is not defined"
     ]
    }
   ],
   "source": [
    "#create  year group \n",
    "ax = ncso_fy_df.plot.bar(figsize = (12,6),  y= ['perc_difference'], legend=None)\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(ncso_fy_df['month'].dt.strftime(\"%Y\"))) #this formats date as string in desired format for x axis, formats here: https://www.ibm.com/support/knowledgecenter/SS6V3G_5.3.1/com.ibm.help.gswapplintug.doc/GSW_strdate.html\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(1, decimals=None)) ##sets y axis labels as percent (and formats correctly i.e. x100)\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_title('Percentage difference between forecasted price concession costs and actual spend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the above, in four out of the five previous financial years the prediction tool correctly estimated within 2%.  The outlying year was 2019-2020, where the underestimation was likely to be due to the significant increase in items in March 2020 due to the onset of the coronavirus pandemic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we improve accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it would appear that the price concession tool is accurate to usually within 2%, as the predictions are less accurate on a monthly basis, are we able to improve this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use monthly National Average Discount Percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the price concessions tool was built a few years ago, we decided to use the NADP that was available at the time (7.2%).  Since then it has fluctuated, and the monthly value (back to 2017) is published on the [NHS BSA website]('https://www.nhsbsa.nhs.uk/prescription-data/understanding-our-data/financial-forecasting').  We can therefore import the data and adjust the prediction calculations accordingly.  We do this in the data below by dividing 7.2% by the actual NADP value, creating a weighting value to adjust the predicted actual cost calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import NADP data (to Feb 2023)\n",
    "#importfile = os.path.join(\"..\",\"data\",\"nadp_fixed.csv\") #define the name of the NADP import file\n",
    "#nadp_df = pd.read_csv(importfile) #import NADP\n",
    "#nadp_df['month'] = nadp_df['month'].astype('datetime64[ns]') #ensure correct date format\n",
    "#nadp_df['nadp_weighting'] = (1-(nadp_df['nadp']/100))/0.928 #create weighting of \"true\" weighting for month vs assumed 7.2%\n",
    "#ncso_fy_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "url = 'https://www.nhsbsa.nhs.uk/prescription-data/understanding-our-data/financial-forecasting' #url for NADP\n",
    "dfs = pd.read_html(url,match='National Average Discount Percentage') #scrape nadp data from table\n",
    "nadp = []\n",
    "for i in range(len(dfs)):\n",
    "    nadp.append(dfs[i])\n",
    "nadp_df = pd.concat(nadp)\n",
    "nadp_df.rename(columns={\"Used for Reports in\": \"month\", \"National Average Discount Percentage\": \"nadp\"}, inplace=True) #rename columns to more manageable names\n",
    "nadp_df['month'] = nadp_df['month'].str[:3] + \" \" + nadp_df['month'].str[-2:] # there was inconsistencies in date naming, so create standardised mmm yy\n",
    "\n",
    "def date_convert(date_to_convert):\n",
    "    return datetime.datetime.strptime(date_to_convert, '%b %y').strftime('%Y-%m-%d') # define datetime function\n",
    "    \n",
    "nadp_df['month'] = nadp_df['month'].apply(date_convert).astype('datetime64[D]') #convert date string to datetime\n",
    "nadp_df['nadp_weighting'] = (1-(nadp_df['nadp']/100))/0.928 #create weighting of \"true\" weighting for month vs assumed 7.2%\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadp_df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncso_sum_df =  ncso_sum_df.merge(nadp_df[[\"month\", \"nadp_weighting\"]]) #add weighting to grouped price concession data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncso_sum_df.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight for difference in days between prediction and actual months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, there are often larger differences between the predicted and actual cost in months that have the most different days, with February being the most obvious.  We can try and weight to change this, by looking at *work days* (Monday-Friday), *dispensing days* (Monday-Saturday), both excluding bank holidays, and work days *including* bank holidays (as patients will tend to pick up prescriptions anyway around Christmas and Easter).  We calculate the number of working and dispensing days below, and apply a weighting to adjust the predicted actual cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bank holiday data from gov.uk and pass to busdays function `holidays=[]`\n",
    "url = 'https://www.gov.uk/bank-holidays.json'\n",
    "bh = pd.read_json(url, orient='index')\n",
    "bankhols = pd.json_normalize(bh.iloc[0][\"events\"]) #flattening json in pandas df\n",
    "#calculate the number of working days (Mon-Fri) and dispensing days (Mon-Sat), excluding bank holidays\n",
    "import calendar\n",
    "dates = ncso_df[[\"month\"]].drop_duplicates() # find data from price concession data\n",
    "dates[\"month\"] = pd.to_datetime(dates[\"month\"])\n",
    "dates[\"year\"] = dates[\"month\"].dt.year\n",
    "dates[\"mon\"] = dates[\"month\"].dt.month\n",
    "d = []\n",
    "for row in dates.itertuples():\n",
    "    y = row.year\n",
    "    m = row.mon\n",
    "    day = calendar.monthrange(y,m)[1]\n",
    "    d.append(str(y)+\"-\"+str(m)+\"-\"+str(day))\n",
    "d = pd.Series(d, name=\"enddates\")\n",
    "d = pd.to_datetime(d, format=\"%Y/%m/%d\")\n",
    "begindates = pd.Series(dates[\"month\"]).values.astype('datetime64[D]')\n",
    "enddates = pd.Series(d).values.astype('datetime64[D]') + 1 #busday_count function doesn't include the end day, so you have to add one day to the series.\n",
    "#######\n",
    "# find business days in month\n",
    "dates[\"workdays\"] = np.busday_count(begindates, enddates, weekmask = 'Mon Tue Wed Thu Fri', holidays=bankhols[\"date\"].values.astype('datetime64[D]')) #Mon-Fri, excluding bank holidays\n",
    "dates[\"nobhworkdays\"] =np.busday_count(begindates, enddates, weekmask = 'Mon Tue Wed Thu Fri') #Mon-Fri, including bank holidays\n",
    "dates[\"dispdays\"] = np.busday_count(begindates, enddates, weekmask = 'Mon Tue Wed Thu Fri Sat', holidays=bankhols[\"date\"].values.astype('datetime64[D]'))#Mon-Sat, excluding bank holidays\n",
    "#dates = dates.set_index(pd.DatetimeIndex(dates['month']))\n",
    "dates['workdays_predict_weighting'] = dates['workdays']/dates['workdays'].shift(2) #calculate weighting to apply for workdays, comparing actual month with data used from two months previously\n",
    "dates['nobhworkdays_predict_weighting'] = dates['nobhworkdays']/dates['nobhworkdays'].shift(2) #calculate weighting to apply for workdays, comparing actual month with data used from two months previously\n",
    "dates['dispdays_predict_weighting'] = dates['dispdays']/dates['dispdays'].shift(2) #calculate weighting to apply for dispensing days, comparing actual month with data used from two months previously\n",
    "#dates = dates.set_index('month')\n",
    "dates = dates.sort_values(by=['month']) #sort values by month for chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also weight the effect that number of days in a month has by looking at the number of items prescribed in each month in six major chapters of the BNF, and see how it changes throughout the year, using the methodology below.  We are using five years worth of data, ending in February 2020, as the pandemic affected the number of items prescribed per month from March 2020 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average proportion of prescriptions per monnth in major rx chapters\n",
    "sql = \"\"\"\n",
    "SELECT\n",
    "  EXTRACT (month\n",
    "  FROM\n",
    "    rx.month) AS mon, #create month of the year only\n",
    "  SUM(rx.items /total_rx.total_items)/(1/12) AS proportion #calculate the relative number of prescriptions dispensed in a month, compared with fixed one-twelth\n",
    "FROM\n",
    "  hscic.normalised_prescribing AS rx,\n",
    "  (\n",
    "  SELECT\n",
    "    SUM(items) AS total_items\n",
    "  FROM\n",
    "    hscic.normalised_prescribing\n",
    "  WHERE\n",
    "    month BETWEEN'2016-03-01'\n",
    "    AND '2020-02-01'\n",
    "    AND SUBSTR(bnf_code,0,2) IN ('01',\n",
    "      '02',\n",
    "      '03',\n",
    "      '04',\n",
    "      '06',\n",
    "      '10'))AS total_rx\n",
    "WHERE\n",
    "  month BETWEEN'2016-03-01'\n",
    "  AND '2020-02-01'\n",
    "  AND SUBSTR(bnf_code,0,2) IN ('01',\n",
    "    '02',\n",
    "    '03',\n",
    "    '04', \n",
    "    '06',\n",
    "    '10')\n",
    "GROUP BY\n",
    "  mon\n",
    "\"\"\"\n",
    "\n",
    "exportfile = os.path.join(\"..\",\"data\",\"annual_profile_df.csv\")\n",
    "annual_profile_df = bq.cached_read(sql, csv_path=exportfile, use_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the profile data to the existing date dataframe\n",
    "dates = pd.merge(dates, annual_profile_df, on=[\"mon\"]) #merge the profile data into the dates df\n",
    "dates = dates.set_index('month')\n",
    "dates = dates.sort_values(by=['month']) #sort values by month for chart in order to allow calculation of weighting from 2 months earlier\n",
    "dates['profile_weighting'] = dates['proportion']/dates['proportion'].shift(2) # calculate difference in profile proportions\n",
    "dates.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing different weightings on accuracy of price concessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to add the date weighting data to the price concession data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncso_sum_df =  ncso_sum_df.merge(dates[[\"month\", \"workdays_predict_weighting\",\"nobhworkdays_predict_weighting\",\"dispdays_predict_weighting\",\"profile_weighting\"]]) #add weighting to grouped price concession data\n",
    "ncso_sum_df.head(200) #show updated dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to see whether the updated NADP improves the prediction further, by calculating the impact of the NADP weighting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncso_sum_df[\"nadp_predicted_actual_cost\"] = ncso_sum_df[\"predicted_actual_cost\"] * ncso_sum_df[\"nadp_weighting\"] # calculate the predicted actual cost using NADP weighting\n",
    "ncso_sum_df[\"nadp_prediction_difference\"] = ncso_sum_df[\"actual_cost\"] - ncso_sum_df[\"nadp_predicted_actual_cost\"] # calculate #difference using NADP\n",
    "ncso_sum_df['nadp_perc_difference'] = ncso_sum_df['nadp_prediction_difference'] / ncso_sum_df['actual_cost'] #calculate percentage difference using NADP\n",
    "ncso_sum_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create chart\n",
    "ax = ncso_sum_df.plot.bar(figsize = (12,6), y= ['perc_difference', 'nadp_perc_difference'], legend=True)\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(ncso_sum_df['month'].dt.strftime(\"%b %Y\"))) #this formats date as string in desired format for x axis, formats here: https://www.ibm.com/support/knowledgecenter/SS6V3G_5.3.1/com.ibm.help.gswapplintug.doc/GSW_strdate.html\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(1, decimals=None)) ##sets y axis labels as percent (and formats correctly i.e. x100)\n",
    "ax.set_title('Percentage difference between forecasted price concession costs and actual spend, using NAPD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create financial year grouping\n",
    "ncso_fy_df = ncso_sum_df.groupby([pd.Grouper(key='month', freq=\"Y\")])[[\"actual_cost\",\"predicted_actual_cost\",\"prediction_difference\", \"nadp_predicted_actual_cost\",\"nadp_prediction_difference\"]].sum() #groups by financial year\n",
    "ncso_fy_df['perc_difference'] = ncso_fy_df['prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference\n",
    "ncso_fy_df['nadp_perc_difference'] = ncso_fy_df['nadp_prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference with NAPD\n",
    "ncso_fy_df.reset_index(inplace=True)\n",
    "#ncso_fy_df = ncso_fy_df.loc[ncso_fy_df[\"month\"].between(\"2017-04-01\", \"2022-03-31\")]\n",
    "ncso_fy_df = ncso_fy_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create financial year group \n",
    "ax = ncso_fy_df.plot.bar(figsize = (12,6),  y= ['perc_difference','nadp_perc_difference'], legend=True)\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(ncso_fy_df['month'].dt.strftime(\"%b %Y\"))) #this formats date as string in desired format for x axis, formats here: https://www.ibm.com/support/knowledgecenter/SS6V3G_5.3.1/com.ibm.help.gswapplintug.doc/GSW_strdate.html\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(1, decimals=None)) ##sets y axis labels as percent (and formats correctly i.e. x100)\n",
    "ax.set_xlabel(\"Financial Year ending\")\n",
    "ax.set_title('Percentage difference between forecasted price concession costs and actual spend (financial year) NADP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the graph above that there is a *slight* improvement for most financial years by adding in an adjustment for correct NADP, rather than the fixed value we currently use.  The improvement appears to increase with time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate how the different weightings for adjusting for days in the month affect the accuracy of the prediction, using the monthly NADP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "ncso_sum_df[\"profile_predicted_actual_cost\"] = ncso_sum_df[\"predicted_actual_cost\"] * ncso_sum_df[\"profile_weighting\"]\n",
    "ncso_sum_df[\"profile_prediction_difference\"] = ncso_sum_df[\"profile_predicted_actual_cost\"] - ncso_sum_df[\"actual_cost\"]\n",
    "ncso_sum_df[\"perc_profile_prediction_difference\"] = ncso_sum_df[\"profile_prediction_difference\"] / ncso_sum_df[\"actual_cost\"]\n",
    "\n",
    "ncso_sum_df[\"profile_nadp_predicted_actual_cost\"] = ncso_sum_df[\"predicted_actual_cost\"] * ncso_sum_df[\"nadp_weighting\"] * ncso_sum_df[\"profile_weighting\"]\n",
    "ncso_sum_df[\"profile_nadp_prediction_difference\"] = ncso_sum_df[\"profile_nadp_predicted_actual_cost\"] - ncso_sum_df[\"actual_cost\"]\n",
    "ncso_sum_df[\"perc_profile_nadp_prediction_difference\"] = ncso_sum_df[\"profile_nadp_prediction_difference\"] / ncso_sum_df[\"actual_cost\"]\n",
    "\n",
    "ncso_sum_df[\"dispdays_nadp_predicted_actual_cost\"] = ncso_sum_df[\"predicted_actual_cost\"] * ncso_sum_df[\"nadp_weighting\"] * ncso_sum_df[\"dispdays_predict_weighting\"]\n",
    "ncso_sum_df[\"dispdays_nadp_prediction_difference\"] = ncso_sum_df[\"dispdays_nadp_predicted_actual_cost\"] - ncso_sum_df[\"actual_cost\"]\n",
    "ncso_sum_df[\"perc_dispdays_nadp_prediction_difference\"] = ncso_sum_df[\"dispdays_nadp_prediction_difference\"] / ncso_sum_df[\"actual_cost\"]\n",
    "\n",
    "ncso_sum_df[\"workdays_nadp_predicted_actual_cost\"] = ncso_sum_df[\"predicted_actual_cost\"] * ncso_sum_df[\"nadp_weighting\"] * ncso_sum_df[\"workdays_predict_weighting\"]\n",
    "ncso_sum_df[\"workdays_nadp_prediction_difference\"] = ncso_sum_df[\"workdays_nadp_predicted_actual_cost\"] - ncso_sum_df[\"actual_cost\"]\n",
    "ncso_sum_df[\"perc_workdays_nadp_prediction_difference\"] = ncso_sum_df[\"workdays_nadp_prediction_difference\"] / ncso_sum_df[\"actual_cost\"]\n",
    "\n",
    "ncso_sum_df[\"nobhworkdays_nadp_predicted_actual_cost\"] = ncso_sum_df[\"predicted_actual_cost\"] * ncso_sum_df[\"nadp_weighting\"] * ncso_sum_df[\"nobhworkdays_predict_weighting\"]\n",
    "ncso_sum_df[\"nobhworkdays_nadp_prediction_difference\"] = ncso_sum_df[\"nobhworkdays_nadp_predicted_actual_cost\"] - ncso_sum_df[\"actual_cost\"]\n",
    "ncso_sum_df[\"perc_nobhworkdays_nadp_prediction_difference\"] = ncso_sum_df[\"nobhworkdays_nadp_prediction_difference\"] / ncso_sum_df[\"actual_cost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create financial year grouping\n",
    "ncso_fy_df = ncso_sum_df.groupby([pd.Grouper(key='month', freq=\"A-MAR\")])[[\"actual_cost\",\"predicted_actual_cost\",\"prediction_difference\",\"nadp_predicted_actual_cost\",\"profile_predicted_actual_cost\",\"profile_prediction_difference\",\"profile_nadp_predicted_actual_cost\",\"profile_nadp_prediction_difference\",\"dispdays_nadp_predicted_actual_cost\",\"dispdays_nadp_prediction_difference\",\"workdays_nadp_predicted_actual_cost\",\"workdays_nadp_prediction_difference\",\"nobhworkdays_nadp_predicted_actual_cost\",\"nobhworkdays_nadp_prediction_difference\"]].sum() #groups by financial year\n",
    "ncso_fy_df['perc_difference'] = ncso_fy_df['prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference\n",
    "ncso_fy_df['perc_difference_profile'] = ncso_fy_df['profile_prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference \n",
    "ncso_fy_df['perc_difference_nadp_profile'] = ncso_fy_df['profile_nadp_prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference\n",
    "ncso_fy_df['perc_difference_nadp_dispdays'] = ncso_fy_df['dispdays_nadp_prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference \n",
    "ncso_fy_df['perc_difference_nadp_workdays'] = ncso_fy_df['workdays_nadp_prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference \n",
    "ncso_fy_df['perc_difference_nadp_nobhworkdays'] = ncso_fy_df['nobhworkdays_nadp_prediction_difference'] / ncso_fy_df['actual_cost'] #recalculate percentage difference \n",
    "ncso_fy_df.reset_index(inplace=True)\n",
    "#ncso_fy_df = ncso_fy_df.loc[ncso_fy_df[\"month\"].between(\"2017-04-01\", \"2022-03-31\")]\n",
    "ncso_fy_df = ncso_fy_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create financial year group \n",
    "ax = ncso_fy_df.plot.bar(figsize = (12,6), y= ['perc_difference','perc_difference_profile','perc_difference_nadp_profile', 'perc_difference_nadp_dispdays','perc_difference_nadp_workdays','perc_difference_nadp_nobhworkdays'], legend=True)\n",
    "ax.xaxis.set_major_formatter(plt.FixedFormatter(ncso_fy_df['month'].dt.strftime(\"%b %Y\"))) #this formats date as string in desired format for x axis, formats here: https://www.ibm.com/support/knowledgecenter/SS6V3G_5.3.1/com.ibm.help.gswapplintug.doc/GSW_strdate.html\n",
    "ax.yaxis.set_major_formatter(ticker.PercentFormatter(1, decimals=None)) ##sets y axis labels as percent (and formats correctly i.e. x100)\n",
    "ax.set_xlabel(\"Financial Year ending\")\n",
    "ax.set_title('Percentage difference between forecasted price concession costs and actual spend (financial year)\\n using different methodologies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, adjusting for number of days in a month has a minimal impact on the accuracy of the prediction tool.  It appears that using both the NADP profile and the number of working days in the month has the closest prediction.  Financial Year 2019-2020 should be excluded due to the impact of the pandemic in March 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OpenPrescribing.net price concessions prediction tool appears to be highly accurate when using the current methodology.  For the previous 5 years this is usually within 2% in a financial year, with 2019-2020 being an outlier for well-documented reasons.\n",
    "2% is certainly accurate enough for planning and awareness in NHS organisations, particularly when the tool is able to identify areas of increased spend as soon as the price concessions have been released on a daily basis.\n",
    "\n",
    "There is the opportunitity to _slightly_ improve the methodology, in two ways:\n",
    "- We should consider using the current monthyl NADP profile, as opposed to the 7.2% fixed value we currently use.  This could be scraped on a monthly basis from the NHSBSA website.\n",
    "- We could consider number of workdays (excluding bank holidays) to further improve the accuracy.  This may require greater redesign of the tool.\n",
    "\n",
    "It's important to note that, given the over 98% accuracy within a financial year, that both of these changes are marginal, and may not be considered a priroity at this time."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.3.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
